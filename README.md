# Human-Attention-in-Image-Captioning-Dataset-and-Analysis-ICCV-2019
## Introduction
This is the github page for my ICCV 2019 paper ([link](https://arxiv.org/abs/1903.02501)).
We provide the the link of the data we collected in the paper:
![picture](/fg/data.png)
[corpus1](https://drive.google.com/drive/folders/10XcVGCu-YODq0FjChy2BNfz9oIwTmyQc?usp=sharing): contains 1000 images, and collected data (eye-fixations and verbal description) from 5 native English speakers. This part of data was used for the analysis in the paper.

[corpus2](https://drive.google.com/drive/folders/1ghe3_7tdx2f3ejiKEnv6w_JJ39-9c9eB?usp=sharing): contains 3000 images, and collected data (each image has the eye-fixations from 3 subjects). This part of data was used for developing saliency prediction model under the image captioning task in the paper.
